\relax 
\abx@aux@sortscheme{nty}
\abx@aux@sortnamekeyscheme{global}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\select@language {english}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language {english}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language {english}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language {english}}
\select@language {swedish}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language {swedish}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language {swedish}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language {swedish}}
\select@language {english}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language {english}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language {english}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language {english}}
\abx@aux@cite{audebert_usability_2016}
\abx@aux@cite{zhong_robust_2017-1}
\select@language {swedish}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language {swedish}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language {swedish}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language {swedish}}
\select@language {english}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language {english}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language {english}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language {english}}
\abx@aux@cite{sermanet_overfeat:_2013}
\abx@aux@cite{zeiler_visualizing_2013}
\abx@aux@cite{simonyan_two-stream_2014}
\abx@aux@cite{krizhevsky_imagenet_2012}
\abx@aux@cite{krizhevsky_learning_2009}
\abx@aux@cite{lin_microsoft_2014}
\abx@aux@cite{garcia-garcia_review_2017}
\abx@aux@cite{ronneberger_u-net:_2015}
\abx@aux@cite{yu_unitbox:_2016}
\abx@aux@cite{rahman_optimizing_2016}
\abx@aux@cite{luc_semantic_2016}
\abx@aux@cite{audebert_segment-before-detect:_2017}
\abx@aux@cite{zhao_classification_2007}
\abx@aux@cite{goodfellow_nips_2016}
\abx@aux@cite{ledig_photo-realistic_2016}
\abx@aux@cite{isola_image--image_2016}
\abx@aux@cite{souly_semi_2017}
\abx@aux@cite{xue_segan:_2017}
\abx@aux@cite{yang_automatic_2017}
\abx@aux@cite{rezaei_conditional_2017}
\abx@aux@cite{arbelle_microscopy_2017}
\abx@aux@cite{ruhe_traffic_2003}
\abx@aux@cite{moranduzzo_automatic_2014}
\abx@aux@cite{uto_characterization_2013}
\abx@aux@cite{berni_thermal_2009}
\abx@aux@cite{moranduzzo_lbp-based_2015}
\abx@aux@cite{polzounov_right_2016}
\abx@aux@cite{ammour_deep_2017}
\abx@aux@cite{holt_object-based_2009}
\abx@aux@cite{razakarivony_vehicle_2015}
\abx@aux@cite{zhong_robust_2017}
\abx@aux@cite{sakla_deep_2017}
\abx@aux@cite{ren_faster_2015}
\abx@aux@cite{girshick_fast_2015}
\abx@aux@cite{he_mask_2017}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.1}Research Question}{4}}
\abx@aux@cite{reed_generative_2016}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Generative adversarial networks}{5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Unconditional generative adversarial networks}{5}}
\newlabel{eq:bce}{{2.1}{5}}
\abx@aux@cite{mirza_conditional_2014}
\abx@aux@cite{pathak_context_2016}
\abx@aux@cite{chintala_ganhacks:_2018}
\abx@aux@cite{shi_real-time_2016}
\newlabel{eq:minimax}{{2.3}{6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Conditional generative adversarial networks}{6}}
\newlabel{eq:cgan}{{2.4}{6}}
\newlabel{eq:mce}{{2.5}{6}}
\abx@aux@cite{shelhamer_fully_2016}
\abx@aux@cite{son_retinal_2017}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Training generative adversarial networks}{7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Segmentation networks}{7}}
\abx@aux@cite{li_deepunet:_2017}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Shows the U-Net architecture proposed by Ronneberger \textit  {et al.} \parencite {ronneberger_u-net:_2015}.\relax }}{8}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:unet}{{2.1}{8}}
\abx@aux@cite{simonyan_very_2014}
\abx@aux@cite{he_deep_2015}
\abx@aux@cite{badrinarayanan_segnet:_2015}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}Classification networks}{9}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}VGG Networks}{9}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The VGG16 architecture proposed by \cite {simonyan_very_2014}\relax }}{9}}
\newlabel{fig:vgg}{{2.2}{9}}
\abx@aux@cite{he_identity_2016}
\abx@aux@cite{szegedy_inception-v4_2016}
\abx@aux@cite{wu_wider_2016}
\abx@aux@cite{zagoruyko_wide_2016}
\abx@aux@cite{sudre_generalised_2017}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}ResNet networks}{10}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The 34 layer deep ResNet architecture \parencite {simonyan_very_2014}\relax }}{10}}
\newlabel{fig:vgg}{{2.3}{10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.4}Weight functions and dealing with severely imbalanced datasets}{10}}
\newlabel{eq:wc1}{{2.9}{11}}
\newlabel{eq:wc2}{{2.10}{11}}
\newlabel{eq:pxl_weight}{{2.12}{11}}
\abx@aux@cite{arnab_higher_2015}
\abx@aux@cite{schwing_fully_2015}
\abx@aux@cite{zheng_conditional_2015}
\newlabel{eq:weight}{{2.13}{12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.5}Earlier work}{12}}
\abx@aux@cite{stockman_computer_2001}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Method}{14}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}The segmentation network}{14}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Network architecture}{14}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Shows the proposed vehicle detection and counting pipeline at test time.\relax }}{15}}
\newlabel{fig:pipe}{{3.1}{15}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Border mirroring}{15}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Shows a training image with mirrored borders from the Potsdam dataset. The shaded area will be lost due to unpaded convolutions.\relax }}{15}}
\newlabel{fig:vgg}{{3.2}{15}}
\abx@aux@cite{johnson_cnn-benchmarks:_2018}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Weighting the cross entropy loss}{16}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Shows the ground truth labels and the pixel weight map for a training image.\relax }}{16}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Adding an adversarial loss term}{16}}
\abx@aux@cite{goodfellow_generative_2014}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Shows the sarchitecture of the segmentation network with an adversarial loss at training time.\relax }}{17}}
\newlabel{fig:GAN}{{3.4}{17}}
\@writefile{lol}{\defcounter {refsection}{0}\relax }\@writefile{lol}{\contentsline {lstlisting}{training.py}{19}}
\abx@aux@cite{noauthor_2d_nodate}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Result}{20}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}The datasets}{20}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}The ISPRS Potsdam semantic dataset}{20}}
\abx@aux@cite{noauthor_worldview-3_nodate}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces An example image from the Potsdam dataset with the rgb channel, the height data channel and the ground truth segmentation map.\relax }}{21}}
\newlabel{eq:precision}{{4.1}{21}}
\newlabel{eq:recall}{{4.2}{21}}
\newlabel{eq:f1}{{4.3}{21}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Figure shows the ground truth labels and the pixel weight map for a training image\relax }}{22}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}The VEDAI dataset}{22}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}Weighting the loss function}{24}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Shows the ground truth segmentation, the discrete prediction without a weighted loss and the discrete prediction with a weighted loss. The weighted loss has clearly enforced better segmentation around nearby vehicles.\relax }}{24}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Shows the pixel wise F1 score of the network with the weighted and unweighted loss for the training and validation dataset.\relax }}{25}}
\newlabel{fig:weighted_vs_unweighted}{{4.4}{25}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}Adding an adversarial loss term}{25}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The pixel wise F1 score for the for the training and validation dataset with and without sparse gradients functions.\relax }}{26}}
\newlabel{fig:sparse}{{4.5}{26}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Shows the ground truth segmentation, the continuous prediction without and with and adversarial loss.\relax }}{27}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Shows the pixel wise F1 score with and without an adversarial loss term on the validation dataset.\relax }}{28}}
\newlabel{fig:gan_vs_class}{{4.7}{28}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.4}Comparison with earlier work}{28}}
\newlabel{tab:potsdam}{{4.4}{28}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Shows the comparison between the proposed model and the Segment before you Detect (SBD) model \parencite {audebert_usability_2016} on the Potsdam dataset.  \textbf  {*} The SBD model was evaluated on a Tesla K20 which can at maximum perform $3.52*10^{12}$ 32 bit floating point operations per second. The proposed model was evaluated on a Tesla K80 wich can perform at maximum $8.74*10^{12}$ 32 bit floating point operations per second. Therefore the evaluation time on the SBD model was multiplied with $3.52/8.74\approx 0.4027$ to make a fair comparison. The evaluation time should therefore not be regarded as exact but as an indication of the speed difference between the two models.\relax }}{28}}
\abx@aux@cite{zeiler_visualizing_2014}
\newlabel{tab:vedai}{{4.4}{29}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Shows the comparison between the proposed model and the Faster R-CNN (Z\&F), Faster R-CNN (VGG-16), Fast R-CNN (VGG-16) \parencite {zeiler_visualizing_2014} and the Cascaded Convolutional Neural Networks (CCNN) \parencite {zhong_robust_2017-1} on the Vedai dataset. \textbf  {*} The other models were evaluated by \parencite {zhong_robust_2017-1} on a Titan X which can at maximum perform $11*10^{12}$ 32 bit floating point operations per second. The proposed model was evaluated on a Tesla K80 wich can perform at maximum $8.74*10^{12}$ 32 bit floating point operations per second. Therefore the evaluation time on the compared models were multiplied with $11/8.74\approx 1.2586$ to make a fair comparison. The evaluation time should therefore not be regarded as exact but as an indication of the speed difference between the two models.\relax }}{29}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Discussion}{30}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Bibliography}{31}}
